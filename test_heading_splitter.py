#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•åŸºäºæ ‡é¢˜çš„PDFåˆ†å‰²å™¨
"""

import sys
import os

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from loaders.pdf_loader import PDFLoader
from splitters import HeadingBasedSplitter

def test_heading_splitter():
    """æµ‹è¯•åŸºäºæ ‡é¢˜çš„åˆ†å‰²å™¨"""
    
    print("=" * 80)
    print("æµ‹è¯•åŸºäºæ ‡é¢˜çš„PDFåˆ†å‰²å™¨")
    print("=" * 80)
    
    # 1. åŠ è½½PDFæ–‡æ¡£
    print("\nğŸ“„ åŠ è½½PDFæ–‡æ¡£...")
    loader = PDFLoader("data/å‘˜å·¥æ‰‹å†Œ.pdf")
    documents = loader.load()
    print(f"   å…±åŠ è½½ {len(documents)} é¡µæ–‡æ¡£")
    
    # 2. ä½¿ç”¨åŸºäºæ ‡é¢˜çš„åˆ†å‰²å™¨
    print("\nâœ‚ï¸  ä½¿ç”¨åŸºäºæ ‡é¢˜çš„åˆ†å‰²å™¨...")
    splitter = HeadingBasedSplitter(
        max_chunk_size=1500,
        chunk_overlap=100
    )
    chunks = splitter.split(documents)
    print(f"   å…±ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æœ¬å—")
    
    # 3. æ˜¾ç¤ºæ¯ä¸ªæ–‡æœ¬å—çš„ä¿¡æ¯
    print("\nğŸ“‹ æ–‡æœ¬å—è¯¦æƒ…:")
    print("-" * 80)
    
    for i, chunk in enumerate(chunks, 1):
        content = chunk.page_content
        metadata = chunk.metadata
        
        print(f"\n[æ–‡æœ¬å— {i}]")
        print(f"  é¡µç : {metadata.get('page', 'æœªçŸ¥')}")
        print(f"  é•¿åº¦: {len(content)} å­—ç¬¦")
        print(f"  åˆ†å‰²å™¨ç±»å‹: {metadata.get('splitter_type', 'æœªçŸ¥')}")
        print(f"  æ£€æµ‹åˆ°çš„æ ‡é¢˜æ•°: {metadata.get('headings_count', 0)}")
        
        # æ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
        preview = content[:200].replace('\n', ' ')
        print(f"  å†…å®¹é¢„è§ˆ: {preview}...")
        
        # æ£€æµ‹å¹¶æ˜¾ç¤ºæ ‡é¢˜
        lines = content.split('\n')
        print(f"  æ ‡é¢˜è¡Œ:")
        for line in lines[:5]:  # åªæ˜¾ç¤ºå‰5è¡Œ
            stripped = line.strip()
            if stripped and len(stripped) < 100:  # å¯èƒ½æ˜¯æ ‡é¢˜
                print(f"    - {stripped}")
    
    # 4. ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 80)
    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 80)
    
    total_chars = sum(len(chunk.page_content) for chunk in chunks)
    avg_chars = total_chars / len(chunks) if chunks else 0
    
    print(f"  æ–‡æœ¬å—æ€»æ•°: {len(chunks)}")
    print(f"  æ€»å­—ç¬¦æ•°: {total_chars}")
    print(f"  å¹³å‡æ¯å—å­—ç¬¦æ•°: {avg_chars:.1f}")
    print(f"  æœ€å°å—å­—ç¬¦æ•°: {min(len(chunk.page_content) for chunk in chunks) if chunks else 0}")
    print(f"  æœ€å¤§å—å­—ç¬¦æ•°: {max(len(chunk.page_content) for chunk in chunks) if chunks else 0}")
    
    # 5. å¯¹æ¯”ï¼šä½¿ç”¨é€’å½’åˆ†å‰²å™¨
    print("\n" + "=" * 80)
    print("ğŸ”„ å¯¹æ¯”ï¼šä½¿ç”¨é€’å½’åˆ†å‰²å™¨")
    print("-" * 80)
    
    from splitters import RecursiveTextSplitter
    recursive_splitter = RecursiveTextSplitter(chunk_size=1000, chunk_overlap=200)
    recursive_chunks = recursive_splitter.split(documents)
    
    print(f"  é€’å½’åˆ†å‰²å™¨ç”Ÿæˆ: {len(recursive_chunks)} ä¸ªæ–‡æœ¬å—")
    print(f"  åŸºäºæ ‡é¢˜åˆ†å‰²å™¨ç”Ÿæˆ: {len(chunks)} ä¸ªæ–‡æœ¬å—")
    print(f"  æ–‡æœ¬å—æ•°é‡å˜åŒ–: {len(chunks) - len(recursive_chunks):+d} ({((len(chunks)/len(recursive_chunks)-1)*100):+.1f}%)")
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)

if __name__ == "__main__":
    test_heading_splitter()
