# æµ‹è¯• SiliconFlow LLM

import os
from dotenv import load_dotenv
from src.llms.siliconflow import SiliconFlowLLM

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æµ‹è¯• SiliconFlow LLM
print("=" * 60)
print("æµ‹è¯• SiliconFlow LLM")
print("=" * 60)

try:
    # åˆå§‹åŒ– LLM
    llm = SiliconFlowLLM(
        model="deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
        temperature=0.7
    )
    
    print("\nâœ… SiliconFlow LLM åˆå§‹åŒ–æˆåŠŸ")
    print(f"æ¨¡å‹: {llm.model}")
    print(f"API Base URL: {llm.base_url}")
    
    # æµ‹è¯•ç®€å•è°ƒç”¨
    print("\nğŸ“ æµ‹è¯•ç®€å•è°ƒç”¨...")
    response = llm.invoke("ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚")
    print(f"å“åº”: {response}")
    
    # æµ‹è¯•æ¶ˆæ¯åˆ—è¡¨æ ¼å¼
    print("\nğŸ“ æµ‹è¯•æ¶ˆæ¯åˆ—è¡¨æ ¼å¼...")
    from langchain.schema import SystemMessage, HumanMessage
    
    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£é—®ç­”åŠ©æ‰‹ã€‚"),
        HumanMessage(content="ä»€ä¹ˆæ˜¯RAGï¼Ÿ")
    ]
    
    response = llm.invoke(messages)
    print(f"å“åº”: {response.content}")
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    
except Exception as e:
    print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
    print("\nğŸ’¡ è¯·ç¡®ä¿ï¼š")
    print("1. å·²åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® SILICONFLOW_API_KEY")
    print("2. API Key æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿçš„é¢åº¦")
    print("3. ç½‘ç»œè¿æ¥æ­£å¸¸")

print("=" * 60)
