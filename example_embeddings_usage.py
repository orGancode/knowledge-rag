#!/usr/bin/env python3
"""
ä½¿ç”¨å‘é‡åŒ–åŠŸèƒ½çš„ç¤ºä¾‹è„šæœ¬
"""

import sys
import os

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from embeddings import OllamaEmbeddings, OpenAIEmbeddings, HuggingFaceEmbeddings

def main():
    print("å‘é‡åŒ–åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹\n")
    
    # ç¤ºä¾‹æ–‡æœ¬
    sample_text = "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚"
    sample_documents = [
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚",
        "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä¸“æ³¨äºè®¡ç®—æœºä¸äººç±»è¯­è¨€ä¹‹é—´çš„äº¤äº’ã€‚"
    ]
    
    # 1. ä½¿ç”¨ Ollama åµŒå…¥æ¨¡å‹
    print("1. ä½¿ç”¨ Ollama åµŒå…¥æ¨¡å‹ (nomic-embed-text)")
    print("-" * 50)
    try:
        ollama_embeddings = OllamaEmbeddings(model="nomic-embed-text")
        
        # åµŒå…¥å•ä¸ªæŸ¥è¯¢
        query_vector = ollama_embeddings.embed_query(sample_text)
        print(f"æŸ¥è¯¢æ–‡æœ¬: {sample_text}")
        print(f"å‘é‡ç»´åº¦: {len(query_vector)}")
        print(f"å‘é‡å‰5ä¸ªå€¼: {query_vector[:5]}")
        
        # åµŒå…¥å¤šä¸ªæ–‡æ¡£
        doc_vectors = ollama_embeddings.embed_documents(sample_documents)
        print(f"\næ–‡æ¡£æ•°é‡: {len(doc_vectors)}")
        print(f"æ¯ä¸ªæ–‡æ¡£å‘é‡ç»´åº¦: {len(doc_vectors[0])}")
        print("ç¬¬ä¸€ä¸ªæ–‡æ¡£å‘é‡å‰5ä¸ªå€¼:", doc_vectors[0][:5])
        
        print("\nâœ… Ollama åµŒå…¥ç¤ºä¾‹æˆåŠŸå®Œæˆ!")
    except Exception as e:
        print(f"âŒ Ollama åµŒå…¥ç¤ºä¾‹å¤±è´¥: {str(e)}")
    
    print("\n" + "="*60 + "\n")
    
    # 2. ä½¿ç”¨ HuggingFace åµŒå…¥æ¨¡å‹
    print("2. ä½¿ç”¨ HuggingFace åµŒå…¥æ¨¡å‹ (sentence-transformers/all-MiniLM-L6-v2)")
    print("-" * 50)
    try:
        hf_embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # åµŒå…¥å•ä¸ªæŸ¥è¯¢
        query_vector = hf_embeddings.embed_query(sample_text)
        print(f"æŸ¥è¯¢æ–‡æœ¬: {sample_text}")
        print(f"å‘é‡ç»´åº¦: {len(query_vector)}")
        print(f"å‘é‡å‰5ä¸ªå€¼: {query_vector[:5]}")
        
        # åµŒå…¥å¤šä¸ªæ–‡æ¡£
        doc_vectors = hf_embeddings.embed_documents(sample_documents)
        print(f"\næ–‡æ¡£æ•°é‡: {len(doc_vectors)}")
        print(f"æ¯ä¸ªæ–‡æ¡£å‘é‡ç»´åº¦: {len(doc_vectors[0])}")
        print("ç¬¬ä¸€ä¸ªæ–‡æ¡£å‘é‡å‰5ä¸ªå€¼:", doc_vectors[0][:5])
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        model_info = hf_embeddings.get_model_info()
        print(f"\næ¨¡å‹ä¿¡æ¯: {model_info}")
        
        # è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
        similarity_score = hf_embeddings.similarity(
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†",
            "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯"
        )
        print(f"\næ–‡æœ¬ç›¸ä¼¼åº¦åˆ†æ•°: {similarity_score:.4f}")
        
        print("\nâœ… HuggingFace åµŒå…¥ç¤ºä¾‹æˆåŠŸå®Œæˆ!")
    except Exception as e:
        print(f"âŒ HuggingFace åµŒå…¥ç¤ºä¾‹å¤±è´¥: {str(e)}")
    
    print("\n" + "="*60 + "\n")
    
    # 3. ä½¿ç”¨ HuggingFace é«˜çº§åŠŸèƒ½
    print("3. ä½¿ç”¨ HuggingFace é«˜çº§åŠŸèƒ½ (å¤šè¯­è¨€æ¨¡å‹)")
    print("-" * 50)
    try:
        # ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒä¸­æ–‡
        hf_advanced = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            device="auto",
            encode_kwargs={
                "batch_size": 16,
                "show_progress_bar": True,
                "normalize_embeddings": True
            }
        )
        
        # ä¸­æ–‡æ–‡æœ¬ç¤ºä¾‹
        chinese_texts = [
            "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ã€‚",
            "æœºå™¨å­¦ä¹ ç®—æ³•å¯ä»¥è‡ªåŠ¨ä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ã€‚",
            "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œã€‚"
        ]
        
        # åµŒå…¥ä¸­æ–‡æ–‡æœ¬
        chinese_vectors = hf_advanced.embed_documents(chinese_texts)
        print(f"ä¸­æ–‡æ–‡æ¡£æ•°é‡: {len(chinese_vectors)}")
        print(f"æ¯ä¸ªæ–‡æ¡£å‘é‡ç»´åº¦: {len(chinese_vectors[0])}")
        
        # è®¡ç®—ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦
        similarity_score = hf_advanced.similarity(
            "äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ å¯†åˆ‡ç›¸å…³ã€‚",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ã€‚"
        )
        print(f"\nä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦åˆ†æ•°: {similarity_score:.4f}")
        
        # è·å–é«˜çº§æ¨¡å‹ä¿¡æ¯
        advanced_model_info = hf_advanced.get_model_info()
        print(f"\nå¤šè¯­è¨€æ¨¡å‹ä¿¡æ¯: {advanced_model_info}")
        
        print("\nâœ… HuggingFace é«˜çº§åŠŸèƒ½ç¤ºä¾‹æˆåŠŸå®Œæˆ!")
    except Exception as e:
        print(f"âŒ HuggingFace é«˜çº§åŠŸèƒ½ç¤ºä¾‹å¤±è´¥: {str(e)}")
    
    print("\n" + "="*60 + "\n")
    
    # 4. ä½¿ç”¨ OpenAI åµŒå…¥æ¨¡å‹ (å¦‚æœæœ‰APIå¯†é’¥)
    print("4. ä½¿ç”¨ OpenAI åµŒå…¥æ¨¡å‹ (text-embedding-3-small)")
    print("-" * 50)
    try:
        if os.getenv("OPENAI_API_KEY"):
            openai_embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
            
            # åµŒå…¥å•ä¸ªæŸ¥è¯¢
            query_vector = openai_embeddings.embed_query(sample_text)
            print(f"æŸ¥è¯¢æ–‡æœ¬: {sample_text}")
            print(f"å‘é‡ç»´åº¦: {len(query_vector)}")
            print(f"å‘é‡å‰5ä¸ªå€¼: {query_vector[:5]}")
            
            # åµŒå…¥å¤šä¸ªæ–‡æ¡£
            doc_vectors = openai_embeddings.embed_documents(sample_documents)
            print(f"\næ–‡æ¡£æ•°é‡: {len(doc_vectors)}")
            print(f"æ¯ä¸ªæ–‡æ¡£å‘é‡ç»´åº¦: {len(doc_vectors[0])}")
            print("ç¬¬ä¸€ä¸ªæ–‡æ¡£å‘é‡å‰5ä¸ªå€¼:", doc_vectors[0][:5])
            
            print("\nâœ… OpenAI åµŒå…¥ç¤ºä¾‹æˆåŠŸå®Œæˆ!")
        else:
            print("âš ï¸ æœªæ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡ OpenAI ç¤ºä¾‹")
    except Exception as e:
        print(f"âŒ OpenAI åµŒå…¥ç¤ºä¾‹å¤±è´¥: {str(e)}")
    
    print("\n" + "="*60)
    print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
    print("1. OllamaEmbeddings: ç”¨äºæœ¬åœ° Ollama æ¨¡å‹ï¼Œé»˜è®¤ä½¿ç”¨ nomic-embed-text")
    print("2. HuggingFaceEmbeddings: ç”¨äº HuggingFace ä¸Šçš„é¢„è®­ç»ƒæ¨¡å‹")
    print("3. HuggingFaceEmbeddings é«˜çº§åŠŸèƒ½: æ”¯æŒå¤šè¯­è¨€ã€è‡ªå®šä¹‰é…ç½®ã€ç›¸ä¼¼åº¦è®¡ç®—ç­‰")
    print("4. OpenAIEmbeddings: ç”¨äº OpenAI çš„åµŒå…¥æ¨¡å‹ï¼Œéœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    print("\nğŸš€ HuggingFaceEmbeddings æ–°åŠŸèƒ½:")
    print("- è‡ªåŠ¨è®¾å¤‡é€‰æ‹© (CPU/GPU)")
    print("- æ¨¡å‹ç¼“å­˜å’Œæ‰¹å¤„ç†ä¼˜åŒ–")
    print("- æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—")
    print("- æ¨¡å‹ä¿¡æ¯è·å–")
    print("- å¤šè¯­è¨€æ”¯æŒ")
    print("- è‡ªå®šä¹‰ç¼–ç å‚æ•°")

if __name__ == "__main__":
    main()