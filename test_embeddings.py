#!/usr/bin/env python3
"""
æµ‹è¯•å‘é‡åŒ–åŠŸèƒ½çš„è„šæœ¬
"""

import sys
import os

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from embeddings import OllamaEmbeddings, HuggingFaceEmbeddings
# from embeddings import OllamaEmbeddings, OpenAIEmbeddings, HuggingFaceEmbeddings

def test_ollama_embeddings():
    """æµ‹è¯•Ollamaå‘é‡åŒ–åŠŸèƒ½"""
    print("æµ‹è¯• OllamaEmbeddings (nomic-embed-text)...")
    
    try:
        # åˆå§‹åŒ–OllamaåµŒå…¥æ¨¡å‹ï¼Œä½¿ç”¨ä¸“é—¨çš„åµŒå…¥æ¨¡å‹
        embeddings = OllamaEmbeddings(model="nomic-embed-text")
        
        # æµ‹è¯•å•ä¸ªæ–‡æœ¬å‘é‡åŒ–
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯å‘é‡åŒ–åŠŸèƒ½ã€‚"
        query_embedding = embeddings.embed_query(test_text)
        print(f"æŸ¥è¯¢æ–‡æœ¬å‘é‡ç»´åº¦: {len(query_embedding)}")
        print(f"æŸ¥è¯¢æ–‡æœ¬å‘é‡å‰5ä¸ªå€¼: {query_embedding[:5]}")
        
        # æµ‹è¯•æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–
        test_texts = [
            "è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ã€‚",
            "è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œå†…å®¹ç•¥æœ‰ä¸åŒã€‚",
            "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚"
        ]
        doc_embeddings = embeddings.embed_documents(test_texts)
        print(f"æ–‡æ¡£å‘é‡æ•°é‡: {len(doc_embeddings)}")
        print(f"æ¯ä¸ªæ–‡æ¡£å‘é‡ç»´åº¦: {len(doc_embeddings[0])}")
        print(f"ç¬¬ä¸€ä¸ªæ–‡æ¡£å‘é‡å‰5ä¸ªå€¼: {doc_embeddings[0][:5]}")
        
        print("âœ… OllamaEmbeddings æµ‹è¯•æˆåŠŸ!")
        return True
    except Exception as e:
        print(f"âŒ OllamaEmbeddings æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

# def test_openai_embeddings():
#     """æµ‹è¯•OpenAIå‘é‡åŒ–åŠŸèƒ½"""
#     print("\næµ‹è¯• OpenAIEmbeddings...")
#
#     try:
#         # æ£€æŸ¥æ˜¯å¦æœ‰APIå¯†é’¥
#         if not os.getenv("OPENAI_API_KEY"):
#             print("âš ï¸ æœªæ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè·³è¿‡ OpenAI æµ‹è¯•")
#             return True
#
#         # åˆå§‹åŒ–OpenAIåµŒå…¥æ¨¡å‹
#         embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
#
#         # æµ‹è¯•å•ä¸ªæ–‡æœ¬å‘é‡åŒ–
#         test_text = "This is a test text for embedding verification."
#         query_embedding = embeddings.embed_query(test_text)
#         print(f"æŸ¥è¯¢æ–‡æœ¬å‘é‡ç»´åº¦: {len(query_embedding)}")
#         print(f"æŸ¥è¯¢æ–‡æœ¬å‘é‡å‰5ä¸ªå€¼: {query_embedding[:5]}")
#
#         # æµ‹è¯•æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–
#         test_texts = [
#             "This is the first test document.",
#             "This is the second test document with slightly different content.",
#             "Artificial intelligence is a branch of computer science."
#         ]
#         doc_embeddings = embeddings.embed_documents(test_texts)
#         print(f"æ–‡æ¡£å‘é‡æ•°é‡: {len(doc_embeddings)}")
#         print(f"æ¯ä¸ªæ–‡æ¡£å‘é‡ç»´åº¦: {len(doc_embeddings[0])}")
#         print(f"ç¬¬ä¸€ä¸ªæ–‡æ¡£å‘é‡å‰5ä¸ªå€¼: {doc_embeddings[0][:5]}")
#
#         print("âœ… OpenAIEmbeddings æµ‹è¯•æˆåŠŸ!")
#         return True
#     except Exception as e:
#         print(f"âŒ OpenAIEmbeddings æµ‹è¯•å¤±è´¥: {str(e)}")
#         return False

def test_huggingface_embeddings():
    """æµ‹è¯•HuggingFaceå‘é‡åŒ–åŠŸèƒ½"""
    print("\næµ‹è¯• HuggingFaceEmbeddings...")
    
    try:
        # åˆå§‹åŒ–HuggingFaceåµŒå…¥æ¨¡å‹
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # æµ‹è¯•å•ä¸ªæ–‡æœ¬å‘é‡åŒ–
        test_text = "This is a test text for embedding verification."
        query_embedding = embeddings.embed_query(test_text)
        print(f"æŸ¥è¯¢æ–‡æœ¬å‘é‡ç»´åº¦: {len(query_embedding)}")
        print(f"æŸ¥è¯¢æ–‡æœ¬å‘é‡å‰5ä¸ªå€¼: {query_embedding[:5]}")
        
        # æµ‹è¯•æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–
        test_texts = [
            "This is the first test document.",
            "This is the second test document with slightly different content.",
            "Artificial intelligence is a branch of computer science."
        ]
        doc_embeddings = embeddings.embed_documents(test_texts)
        print(f"æ–‡æ¡£å‘é‡æ•°é‡: {len(doc_embeddings)}")
        print(f"æ¯ä¸ªæ–‡æ¡£å‘é‡ç»´åº¦: {len(doc_embeddings[0])}")
        print(f"ç¬¬ä¸€ä¸ªæ–‡æ¡£å‘é‡å‰5ä¸ªå€¼: {doc_embeddings[0][:5]}")
        
        # æµ‹è¯•æ¨¡å‹ä¿¡æ¯è·å–
        model_info = embeddings.get_model_info()
        print(f"æ¨¡å‹ä¿¡æ¯: {model_info}")
        
        # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
        similarity_score = embeddings.similarity(
            "Machine learning is a subset of artificial intelligence.",
            "Deep learning is a type of machine learning."
        )
        print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {similarity_score:.4f}")
        
        print("âœ… HuggingFaceEmbeddings æµ‹è¯•æˆåŠŸ!")
        return True
    except Exception as e:
        print(f"âŒ HuggingFaceEmbeddings æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def test_huggingface_embeddings_advanced():
    """æµ‹è¯•HuggingFaceå‘é‡åŒ–é«˜çº§åŠŸèƒ½"""
    print("\næµ‹è¯• HuggingFaceEmbeddings é«˜çº§åŠŸèƒ½...")
    
    try:
        # æµ‹è¯•ä¸åŒçš„æ¨¡å‹é…ç½®
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            device="auto",
            encode_kwargs={
                "batch_size": 16,
                "show_progress_bar": True,
                "normalize_embeddings": True
            }
        )
        
        # æµ‹è¯•ä¸­æ–‡æ–‡æœ¬
        chinese_texts = [
            "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ã€‚",
            "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚"
        ]
        
        # åµŒå…¥ä¸­æ–‡æ–‡æœ¬
        doc_embeddings = embeddings.embed_documents(chinese_texts)
        print(f"ä¸­æ–‡æ–‡æ¡£å‘é‡æ•°é‡: {len(doc_embeddings)}")
        print(f"æ¯ä¸ªæ–‡æ¡£å‘é‡ç»´åº¦: {len(doc_embeddings[0])}")
        
        # æµ‹è¯•ä¸­æ–‡ç›¸ä¼¼åº¦è®¡ç®—
        similarity_score = embeddings.similarity(
            "äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ å¯†åˆ‡ç›¸å…³ã€‚",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸã€‚"
        )
        print(f"ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦åˆ†æ•°: {similarity_score:.4f}")
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        model_info = embeddings.get_model_info()
        print(f"å¤šè¯­è¨€æ¨¡å‹ä¿¡æ¯: {model_info}")
        
        print("âœ… HuggingFaceEmbeddings é«˜çº§åŠŸèƒ½æµ‹è¯•æˆåŠŸ!")
        return True
    except Exception as e:
        print(f"âŒ HuggingFaceEmbeddings é«˜çº§åŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•å‘é‡åŒ–åŠŸèƒ½...\n")
    
    # æµ‹è¯•å„ç§åµŒå…¥æ¨¡å‹
    results = []
    results.append(test_ollama_embeddings())
    # results.append(test_openai_embeddings())  # æš‚æ—¶æ³¨é‡Šæ‰OpenAIæµ‹è¯•
    results.append(test_huggingface_embeddings())
    results.append(test_huggingface_embeddings_advanced())
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    success_count = sum(results)
    total_count = len(results)
    
    print(f"\næµ‹è¯•æ€»ç»“: {success_count}/{total_count} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if success_count == total_count:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")